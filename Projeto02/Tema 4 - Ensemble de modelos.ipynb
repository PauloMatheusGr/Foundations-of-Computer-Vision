{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble de modelos\n",
    "\n",
    "1. Uma das classes mais desafiadoras do ImageNet é a ladle (concha). Verifique se um conjunto de modelos consegue melhorar a classificação que seria feita por um único modelo\n",
    "2. Use os 5 modelos indicados abaixo para classificar as imagens presentes no diretório \"ladle_n03633091\". Agregue os resultados dos modelos através da média dos resultados dos 5 modelos\n",
    "3. Verifique se há uma melhora do resultado em relação a cada modelo individual\n",
    "4. Para cada imagem, calcule a variação da classificação entre os modelos. Em problemas reais, essa variação pode ser utilizada para estimar o grau de incerteza dos modelos. Você deve definir uma medida de variação\n",
    "5. Treine o modelo de classificação \"efficientnet_b3.in1k\" para identificar imagens da classe ladle. Para isso, considere um problema de duas classes: \"ladle\" e \"other\". \n",
    "\n",
    "Os dados para o projeto estão disponíveis no link: https://www.dropbox.com/scl/fi/5ryjw81wtxtwejadllzsb/tema_4.zip?rlkey=1d44q86ygtflo0tv739j4e8ol&dl=1\n",
    "\n",
    "O diretório \"ladle_n03633091\" possui imagens de conchas. O diretório \"other_classes\" possui 2 imagens de cada uma das 999 outras classes do ImageNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo de aplicação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import timm\n",
    "\n",
    "tags = [\n",
    "    'resnet50.a1_in1k', \n",
    "    'convnext_tiny.in12k_ft_in1k', \n",
    "    'vit_small_patch16_224.augreg_in21k_ft_in1k', \n",
    "    'tf_efficientnetv2_s.in21k_ft_in1k', \n",
    "    'swinv2_tiny_window8_256.ms_in1k'\n",
    "]\n",
    "\n",
    "models = []\n",
    "transforms = []\n",
    "for tag in tags:\n",
    "    model = timm.create_model(tag, pretrained=True)\n",
    "    model.eval()\n",
    "\n",
    "    # Obtenção das transformações a serem aplicadas nas imagens\n",
    "    data_cfg = timm.data.resolve_data_config(model.pretrained_cfg)\n",
    "    transform = timm.data.create_transform(**data_cfg)\n",
    "\n",
    "    models.append(model)\n",
    "    transforms.append(transform)\n",
    "\n",
    "# Imagem aleatória para ilustração\n",
    "x = torch.randint(0, 255, (224, 224, 3))\n",
    "x = Image.fromarray(np.array(x, dtype=np.uint8))\n",
    "probs = []\n",
    "with torch.no_grad():\n",
    "    for transform, model in zip(transforms, models):\n",
    "        x_t = transform(x)\n",
    "        probs.append(model(x_t.unsqueeze(0))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rede a ser utilizada para identificar imagens de concha. Um modelo bem menor que os 5 acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = 'efficientnet_b3.in1k'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vc2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
