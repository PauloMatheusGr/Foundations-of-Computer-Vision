{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento da rede\n",
    "\n",
    "Este notebook aplica todos os conceitos que vimos em um treinamento completo para classificação de imagens. Todas as funções associadas com processamento do dataset foram incluídas no arquivo `dataset.py` e as funções que realizam o treinamento foram incluídas no arquivo `train.py`\n",
    "\n",
    "Este notebook leva algumas horas para rodar em uma GPU, e mais tempo ainda em uma CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula para baixar os dados. Execute apenas uma vez!\n",
    "from torchvision.datasets.utils import download_and_extract_archive\n",
    "\n",
    "def download(root):\n",
    "\n",
    "    url_images = 'https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz'\n",
    "    url_targets = 'https://thor.robots.ox.ac.uk/~vgg/data/pets/annotations.tar.gz'\n",
    "\n",
    "    download_and_extract_archive(url_images, root, remove_finished=False)\n",
    "    download_and_extract_archive(url_targets, root, remove_finished=False)\n",
    "\n",
    "#download('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/dataset.py\", line 28, in __getitem__\n    img = self.transform(img)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/dataset.py\", line 89, in __call__\n    return self.transforms(img)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torchvision/transforms/v2/_container.py\", line 51, in forward\n    outputs = transform(*inputs)\n              ^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torchvision/transforms/v2/_transform.py\", line 51, in forward\n    self._transform(inpt, params) if needs_transform else inpt\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torchvision/transforms/v2/_type_conversion.py\", line 24, in _transform\n    return F.pil_to_tensor(inpt)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torchvision/transforms/functional.py\", line 208, in pil_to_tensor\n    img = torch.as_tensor(np.array(pic, copy=True))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Could not infer dtype of numpy.uint8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Modifica a última camada do modelo para classificar em 2 classes\u001b[39;00m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(model\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39min_features, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m ds_train, ds_valid, logger \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Cada época demora em torno de 6.1 segundos em uma RTX3080\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/train.py:122\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, bs, num_epochs, lr, weight_decay, resize_size, seed, num_workers)\u001b[0m\n\u001b[1;32m    120\u001b[0m best_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, num_epochs):\n\u001b[0;32m--> 122\u001b[0m     loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     loss_valid, perf \u001b[38;5;241m=\u001b[39m valid_step(model, dl_valid, loss_func, accuracy, device)\n\u001b[1;32m    124\u001b[0m     logger\u001b[38;5;241m.\u001b[39mappend((epoch, loss_train, loss_valid, perf))\n",
      "File \u001b[0;32m~/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/train.py:45\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, dl_train, optim, loss_func, scheduler, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Armazenará a média das losses de todos os bathces\u001b[39;00m\n\u001b[1;32m     44\u001b[0m loss_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m---> 45\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdl_train\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/dataset.py\", line 28, in __getitem__\n    img = self.transform(img)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/dataset.py\", line 89, in __call__\n    return self.transforms(img)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torchvision/transforms/v2/_container.py\", line 51, in forward\n    outputs = transform(*inputs)\n              ^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torchvision/transforms/v2/_transform.py\", line 51, in forward\n    self._transform(inpt, params) if needs_transform else inpt\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torchvision/transforms/v2/_type_conversion.py\", line 24, in _transform\n    return F.pil_to_tensor(inpt)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pgirardi/Desktop/Foundations-of-Computer-Vision/M06_classificacao_de_imagens_naturais/venv_vision/lib/python3.12/site-packages/torchvision/transforms/functional.py\", line 208, in pil_to_tensor\n    img = torch.as_tensor(np.array(pic, copy=True))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Could not infer dtype of numpy.uint8\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torchvision import models\n",
    "import train\n",
    "\n",
    "params = {\n",
    "    'bs':256,\n",
    "    'num_epochs':300,\n",
    "    'lr':0.01,\n",
    "    'weight_decay':1e-2,\n",
    "    'resize_size':224,  # Tamanho das imagens de treinamento\n",
    "    'seed':0\n",
    "}\n",
    "model = models.resnet18()\n",
    "# Modifica a última camada do modelo para classificar em 2 classes\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "ds_train, ds_valid, logger = train.train(model, **params)\n",
    "# Cada época demora em torno de 6.1 segundos em uma RTX3080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se necessário, é possível continuar treinando a rede, mesmo após reiniciar o notebook. Bastaria fazermos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import train\n",
    "\n",
    "params = {\n",
    "    'bs':256,\n",
    "    'num_epochs':50,   # Treina por mais 50 épocas\n",
    "    'lr':0.001,        # Learning rate menor do que o treinamento original\n",
    "    'weight_decay':1e-3,\n",
    "    'resize_size':224,  \n",
    "    'seed':1\n",
    "}\n",
    "\n",
    "# Carrega pesos do modelo salvo\n",
    "checkpoint = torch.load('../data/checkpoints/M06/checkpoint.pt')\n",
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "# Treina mais um pouco. A linha está comentada para evitar a execução\n",
    "#ds_train, ds_valid, logger = train.train(model, **params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vc2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
